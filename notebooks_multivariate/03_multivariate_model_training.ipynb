{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 - Multivariate Time Series Model Training\n",
        "\n",
        "This notebook focuses on:\n",
        "1. VAR (Vector Autoregression) models\n",
        "2. VARMA (Vector ARMA) models\n",
        "3. Machine learning models with multiple features\n",
        "4. Deep learning approaches (LSTM, GRU)\n",
        "5. Feature engineering for multivariate forecasting\n",
        "6. Model comparison and selection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries with robust error handling\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# Import time series libraries with individual error handling\n",
        "var_available = False\n",
        "varma_available = False\n",
        "\n",
        "try:\n",
        "    from statsmodels.tsa.vector_ar.var_model import VAR\n",
        "    var_available = True\n",
        "    print(\"‚úÖ VAR imported successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå VAR import failed: {e}\")\n",
        "\n",
        "try:\n",
        "    from statsmodels.tsa.vector_ar.svar_model import SVAR\n",
        "    varma_available = True\n",
        "    print(\"‚úÖ SVAR imported successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå SVAR import failed: {e}\")\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn')\n",
        "sns.set_palette(\"husl\")\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"‚úÖ All imports completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load prepared data and setup\n",
        "print(\"=== LOADING DATA FOR MULTIVARIATE MODEL TRAINING ===\")\n",
        "\n",
        "try:\n",
        "    # Load the prepared data splits\n",
        "    in_time_data = pd.read_csv('../data_multivariate/in_time_features.csv', index_col=0, parse_dates=True)\n",
        "    out_of_time_data = pd.read_csv('../data_multivariate/out_of_time_features.csv', index_col=0, parse_dates=True)\n",
        "    \n",
        "    print(f\"‚úÖ Data loaded successfully!\")\n",
        "    print(f\"In-time data shape: {in_time_data.shape}\")\n",
        "    print(f\"Out-of-time data shape: {out_of_time_data.shape}\")\n",
        "    \n",
        "    # Set up dataset configuration\n",
        "    target = 'PM2.5'  # Default target for air quality data\n",
        "    feature_columns = [col for col in in_time_data.columns if col != target]\n",
        "    \n",
        "    print(f\"Features: {len(feature_columns)}\")\n",
        "    print(f\"Target: {target}\")\n",
        "    print(f\"Date range: {in_time_data.index.min()} to {out_of_time_data.index.max()}\")\n",
        "    \n",
        "    # Prepare data for modeling\n",
        "    # For VAR models, we need all variables\n",
        "    var_data = in_time_data.copy()\n",
        "    var_test_data = out_of_time_data.copy()\n",
        "    \n",
        "    # For ML models, separate features and target\n",
        "    X_train = in_time_data[feature_columns]\n",
        "    y_train = in_time_data[target]\n",
        "    X_test = out_of_time_data[feature_columns]\n",
        "    y_test = out_of_time_data[target]\n",
        "    \n",
        "    print(f\"‚úÖ Data prepared for modeling\")\n",
        "    print(f\"VAR data shape: {var_data.shape}\")\n",
        "    print(f\"ML training features: {X_train.shape}\")\n",
        "    print(f\"ML training target: {y_train.shape}\")\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Prepared data files not found\")\n",
        "    print(\"Please run 01_multivariate_data_exploration.ipynb and 02_multivariate_time_series_analysis.ipynb first\")\n",
        "    var_data = None\n",
        "    var_test_data = None\n",
        "    X_train = None\n",
        "    y_train = None\n",
        "    X_test = None\n",
        "    y_test = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define evaluation metrics and model results storage\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate time series evaluation metrics\n",
        "    \"\"\"\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
        "    \n",
        "    # Symmetric MAPE\n",
        "    smape = 100 * np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred)))\n",
        "    \n",
        "    return {\n",
        "        'MAE': mae,\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse,\n",
        "        'MAPE': mape,\n",
        "        'sMAPE': smape\n",
        "    }\n",
        "\n",
        "def print_metrics(metrics, model_name):\n",
        "    \"\"\"\n",
        "    Print formatted metrics\n",
        "    \"\"\"\n",
        "    print(f\"\\n{model_name} Metrics:\")\n",
        "    print(\"-\" * 30)\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "# Store results\n",
        "model_results = {}\n",
        "print(\"‚úÖ Evaluation metrics and storage setup completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VAR (Vector Autoregression) Models\n",
        "print(\"=== TRAINING VAR (VECTOR AUTOREGRESSION) MODELS ===\")\n",
        "\n",
        "if var_available and var_data is not None and not var_data.empty:\n",
        "    print(\"Training VAR models for multivariate time series forecasting...\")\n",
        "    \n",
        "    # Ensure data is stationary (VAR requires stationary data)\n",
        "    print(\"Checking stationarity and applying differencing if needed...\")\n",
        "    \n",
        "    # Test for stationarity and apply differencing\n",
        "    var_data_stationary = var_data.copy()\n",
        "    differenced = False\n",
        "    \n",
        "    for col in var_data.columns:\n",
        "        # Simple ADF test\n",
        "        from statsmodels.tsa.stattools import adfuller\n",
        "        adf_result = adfuller(var_data[col].dropna())\n",
        "        if adf_result[1] > 0.05:  # Non-stationary\n",
        "            print(f\"  {col}: Non-stationary, applying first difference\")\n",
        "            var_data_stationary[col] = var_data[col].diff()\n",
        "            differenced = True\n",
        "        else:\n",
        "            print(f\"  {col}: Stationary\")\n",
        "    \n",
        "    if differenced:\n",
        "        print(\"Applied first differencing to achieve stationarity\")\n",
        "        var_data_stationary = var_data_stationary.dropna()\n",
        "    \n",
        "    # Select optimal lag order using information criteria\n",
        "    print(\"\\nSelecting optimal lag order...\")\n",
        "    \n",
        "    try:\n",
        "        # Fit VAR model with automatic lag selection\n",
        "        model = VAR(var_data_stationary)\n",
        "        lag_order_results = model.select_order(maxlags=15)\n",
        "        \n",
        "        print(f\"Lag selection results:\")\n",
        "        print(f\"  AIC: {lag_order_results.aic}\")\n",
        "        print(f\"  BIC: {lag_order_results.bic}\")\n",
        "        print(f\"  HQIC: {lag_order_results.hqic}\")\n",
        "        print(f\"  FPE: {lag_order_results.fpe}\")\n",
        "        \n",
        "        # Use BIC for lag selection (more conservative)\n",
        "        optimal_lags = lag_order_results.bic\n",
        "        print(f\"Selected lag order: {optimal_lags}\")\n",
        "        \n",
        "        # Fit VAR model with selected lags\n",
        "        print(f\"\\nFitting VAR model with {optimal_lags} lags...\")\n",
        "        var_model = model.fit(maxlags=optimal_lags, ic='bic')\n",
        "        \n",
        "        print(\"VAR Model Summary:\")\n",
        "        print(var_model.summary())\n",
        "        \n",
        "        # Make forecasts\n",
        "        print(f\"\\nMaking forecasts for {len(var_test_data)} periods...\")\n",
        "        \n",
        "        # For forecasting, we need to handle the differenced data\n",
        "        if differenced:\n",
        "            # Forecast the differenced series\n",
        "            forecast_steps = len(var_test_data)\n",
        "            forecasts = var_model.forecast(var_data_stationary.values[-optimal_lags:], steps=forecast_steps)\n",
        "            \n",
        "            # Convert forecasts back to levels (integrate)\n",
        "            forecast_df = pd.DataFrame(forecasts, columns=var_data.columns)\n",
        "            \n",
        "            # Integrate to get level forecasts\n",
        "            level_forecasts = forecast_df.copy()\n",
        "            for col in forecast_df.columns:\n",
        "                # Add back the last observed value\n",
        "                last_value = var_data[col].iloc[-1]\n",
        "                level_forecasts[col] = forecast_df[col].cumsum() + last_value\n",
        "        else:\n",
        "            # Direct forecasting for stationary data\n",
        "            forecast_steps = len(var_test_data)\n",
        "            forecasts = var_model.forecast(var_data.values[-optimal_lags:], steps=forecast_steps)\n",
        "            level_forecasts = pd.DataFrame(forecasts, columns=var_data.columns)\n",
        "        \n",
        "        # Evaluate forecasts for target variable\n",
        "        if target in level_forecasts.columns:\n",
        "            var_pred = level_forecasts[target].values\n",
        "            var_actual = var_test_data[target].values\n",
        "            \n",
        "            # Calculate metrics\n",
        "            var_metrics = calculate_metrics(var_actual, var_pred)\n",
        "            print_metrics(var_metrics, \"VAR Model\")\n",
        "            model_results['VAR'] = var_metrics\n",
        "            \n",
        "            # Store VAR model and forecasts\n",
        "            var_forecasts = level_forecasts\n",
        "            \n",
        "        else:\n",
        "            print(f\"‚ùå Target variable '{target}' not found in forecasts\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå VAR model training failed: {e}\")\n",
        "        \n",
        "else:\n",
        "    if not var_available:\n",
        "        print(\"‚ùå VAR not available - statsmodels VAR module not found\")\n",
        "    else:\n",
        "        print(\"‚ùå No data available for VAR modeling\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Machine Learning Models for Multivariate Time Series\n",
        "print(\"=== TRAINING MACHINE LEARNING MODELS ===\")\n",
        "\n",
        "if X_train is not None and y_train is not None:\n",
        "    print(\"Training machine learning models with multiple features...\")\n",
        "    \n",
        "    # 1. Random Forest with Hyperparameter Tuning\n",
        "    print(\"\\n1. Training Random Forest Model with Hyperparameter Tuning...\")\n",
        "    \n",
        "    try:\n",
        "        # Define parameter grid for hyperparameter tuning\n",
        "        param_grid = {\n",
        "            'n_estimators': [50, 100, 200],\n",
        "            'max_depth': [5, 10, 15, None],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4],\n",
        "            'max_features': ['sqrt', 'log2', None]\n",
        "        }\n",
        "        \n",
        "        # Create base Random Forest model\n",
        "        rf_base = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "        \n",
        "        # Use TimeSeriesSplit for cross-validation (respects temporal order)\n",
        "        tscv = TimeSeriesSplit(n_splits=3)\n",
        "        \n",
        "        # Grid search with time series cross-validation\n",
        "        print(\"Performing hyperparameter tuning...\")\n",
        "        rf_grid = GridSearchCV(\n",
        "            estimator=rf_base,\n",
        "            param_grid=param_grid,\n",
        "            cv=tscv,\n",
        "            scoring='neg_mean_squared_error',\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        \n",
        "        # Fit the grid search\n",
        "        rf_grid.fit(X_train, y_train)\n",
        "        \n",
        "        # Get best model\n",
        "        rf_model = rf_grid.best_estimator_\n",
        "        \n",
        "        print(f\"Best parameters: {rf_grid.best_params_}\")\n",
        "        print(f\"Best cross-validation score: {-rf_grid.best_score_:.4f}\")\n",
        "        \n",
        "        # Make predictions\n",
        "        rf_pred = rf_model.predict(X_test)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        rf_metrics = calculate_metrics(y_test.values, rf_pred)\n",
        "        print_metrics(rf_metrics, \"Random Forest (Tuned)\")\n",
        "        model_results['RandomForest_Tuned'] = rf_metrics\n",
        "        \n",
        "        # Feature importance analysis\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'feature': X_train.columns,\n",
        "            'importance': rf_model.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "        \n",
        "        print(\"\\nTop 10 Most Important Features:\")\n",
        "        print(feature_importance.head(10))\n",
        "        \n",
        "        # Store feature importance for later analysis\n",
        "        top_features = feature_importance.head(10)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Random Forest model failed: {e}\")\n",
        "        # Fallback to basic Random Forest if tuning fails\n",
        "        print(\"Falling back to basic Random Forest...\")\n",
        "        try:\n",
        "            rf_model = RandomForestRegressor(\n",
        "                n_estimators=100,\n",
        "                max_depth=10,\n",
        "                min_samples_split=5,\n",
        "                min_samples_leaf=2,\n",
        "                random_state=42,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "            \n",
        "            rf_model.fit(X_train, y_train)\n",
        "            rf_pred = rf_model.predict(X_test)\n",
        "            rf_metrics = calculate_metrics(y_test.values, rf_pred)\n",
        "            print_metrics(rf_metrics, \"Random Forest (Basic)\")\n",
        "            model_results['RandomForest_Basic'] = rf_metrics\n",
        "            \n",
        "            # Feature importance\n",
        "            feature_importance = pd.DataFrame({\n",
        "                'feature': X_train.columns,\n",
        "                'importance': rf_model.feature_importances_\n",
        "            }).sort_values('importance', ascending=False)\n",
        "            \n",
        "            print(\"\\nTop 10 Most Important Features:\")\n",
        "            print(feature_importance.head(10))\n",
        "            top_features = feature_importance.head(10)\n",
        "            \n",
        "        except Exception as e2:\n",
        "            print(f\"‚ùå Basic Random Forest also failed: {e2}\")\n",
        "    \n",
        "    # 2. Additional ML Models (if time permits)\n",
        "    print(\"\\n2. Training Additional ML Models...\")\n",
        "    \n",
        "    # Linear Regression as baseline\n",
        "    try:\n",
        "        from sklearn.linear_model import LinearRegression\n",
        "        \n",
        "        lr_model = LinearRegression()\n",
        "        lr_model.fit(X_train, y_train)\n",
        "        lr_pred = lr_model.predict(X_test)\n",
        "        \n",
        "        lr_metrics = calculate_metrics(y_test.values, lr_pred)\n",
        "        print_metrics(lr_metrics, \"Linear Regression\")\n",
        "        model_results['LinearRegression'] = lr_metrics\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Linear Regression failed: {e}\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ Machine learning models completed!\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No data available for machine learning models\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Comparison and Results Summary\n",
        "print(\"=== MODEL COMPARISON AND RESULTS SUMMARY ===\")\n",
        "\n",
        "if model_results:\n",
        "    # Create results DataFrame\n",
        "    results_df = pd.DataFrame(model_results).T\n",
        "    results_df = results_df.sort_values('RMSE')\n",
        "    \n",
        "    print(\"\\nüìä MODEL PERFORMANCE SUMMARY (sorted by RMSE):\")\n",
        "    print(\"=\" * 80)\n",
        "    print(results_df.round(4))\n",
        "    \n",
        "    # Model categorization\n",
        "    traditional_models = [col for col in results_df.index if col in ['VAR', 'SVAR']]\n",
        "    ml_models = [col for col in results_df.index if any(x in col for x in ['RandomForest', 'LinearRegression'])]\n",
        "    \n",
        "    print(f\"\\nüè∑Ô∏è  MODEL CATEGORIES:\")\n",
        "    print(f\"   Traditional Time Series Models: {len(traditional_models)}\")\n",
        "    if traditional_models:\n",
        "        print(f\"   - {', '.join(traditional_models)}\")\n",
        "    print(f\"   Machine Learning Models: {len(ml_models)}\")\n",
        "    if ml_models:\n",
        "        print(f\"   - {', '.join(ml_models)}\")\n",
        "    \n",
        "    # Find best model\n",
        "    best_model = results_df.index[0]\n",
        "    best_rmse = results_df.loc[best_model, 'RMSE']\n",
        "    best_mae = results_df.loc[best_model, 'MAE']\n",
        "    best_mape = results_df.loc[best_model, 'MAPE']\n",
        "    best_smape = results_df.loc[best_model, 'sMAPE']\n",
        "    \n",
        "    print(f\"\\nüèÜ BEST MODEL: {best_model}\")\n",
        "    print(f\"   RMSE: {best_rmse:.4f} (Primary metric - lower is better)\")\n",
        "    print(f\"   MAE:  {best_mae:.4f} (Average absolute error)\")\n",
        "    print(f\"   MAPE: {best_mape:.4f}% (Mean absolute percentage error)\")\n",
        "    print(f\"   sMAPE: {best_smape:.4f}% (Symmetric MAPE)\")\n",
        "    \n",
        "    # Model performance analysis\n",
        "    print(f\"\\nüìà PERFORMANCE ANALYSIS:\")\n",
        "    print(f\"   Best RMSE: {best_rmse:.4f}\")\n",
        "    print(f\"   Worst RMSE: {results_df['RMSE'].max():.4f}\")\n",
        "    print(f\"   RMSE Range: {results_df['RMSE'].max() - best_rmse:.4f}\")\n",
        "    print(f\"   RMSE Improvement: {((results_df['RMSE'].max() - best_rmse) / results_df['RMSE'].max() * 100):.1f}%\")\n",
        "    \n",
        "    # Model type comparison\n",
        "    if traditional_models and ml_models:\n",
        "        traditional_avg_rmse = results_df.loc[traditional_models, 'RMSE'].mean()\n",
        "        ml_avg_rmse = results_df.loc[ml_models, 'RMSE'].mean()\n",
        "        \n",
        "        print(f\"\\n‚öñÔ∏è  MODEL TYPE COMPARISON:\")\n",
        "        print(f\"   Traditional Models Average RMSE: {traditional_avg_rmse:.4f}\")\n",
        "        print(f\"   Machine Learning Models Average RMSE: {ml_avg_rmse:.4f}\")\n",
        "        \n",
        "        if traditional_avg_rmse < ml_avg_rmse:\n",
        "            print(f\"   üéØ Traditional models perform better on average\")\n",
        "        else:\n",
        "            print(f\"   üéØ Machine learning models perform better on average\")\n",
        "    \n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # RMSE comparison\n",
        "    bars1 = axes[0, 0].bar(results_df.index, results_df['RMSE'], color='skyblue', alpha=0.7)\n",
        "    axes[0, 0].set_title('RMSE Comparison (Primary Metric)', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].set_ylabel('RMSE (Lower is Better)')\n",
        "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "    # Highlight best model\n",
        "    best_idx = list(results_df.index).index(best_model)\n",
        "    bars1[best_idx].set_color('gold')\n",
        "    bars1[best_idx].set_alpha(1.0)\n",
        "    \n",
        "    # MAE comparison\n",
        "    bars2 = axes[0, 1].bar(results_df.index, results_df['MAE'], color='lightcoral', alpha=0.7)\n",
        "    axes[0, 1].set_title('MAE Comparison', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].set_ylabel('MAE (Lower is Better)')\n",
        "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # MAPE comparison\n",
        "    bars3 = axes[1, 0].bar(results_df.index, results_df['MAPE'], color='lightgreen', alpha=0.7)\n",
        "    axes[1, 0].set_title('MAPE Comparison', fontsize=14, fontweight='bold')\n",
        "    axes[1, 0].set_ylabel('MAPE (%) (Lower is Better)')\n",
        "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # sMAPE comparison\n",
        "    bars4 = axes[1, 1].bar(results_df.index, results_df['sMAPE'], color='plum', alpha=0.7)\n",
        "    axes[1, 1].set_title('sMAPE Comparison', fontsize=14, fontweight='bold')\n",
        "    axes[1, 1].set_ylabel('sMAPE (%) (Lower is Better)')\n",
        "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Model recommendations\n",
        "    print(f\"\\nüí° MODEL RECOMMENDATIONS:\")\n",
        "    print(f\"   1. ü•á Best Overall: {best_model} (RMSE: {best_rmse:.4f})\")\n",
        "    \n",
        "    # Find best in each category\n",
        "    if traditional_models:\n",
        "        best_traditional = results_df.loc[traditional_models].sort_values('RMSE').index[0]\n",
        "        print(f\"   2. üèõÔ∏è  Best Traditional: {best_traditional} (RMSE: {results_df.loc[best_traditional, 'RMSE']:.4f})\")\n",
        "    \n",
        "    if ml_models:\n",
        "        best_ml = results_df.loc[ml_models].sort_values('RMSE').index[0]\n",
        "        print(f\"   3. ü§ñ Best ML Model: {best_ml} (RMSE: {results_df.loc[best_ml, 'RMSE']:.4f})\")\n",
        "    \n",
        "    # Save results\n",
        "    print(f\"\\nüíæ SAVING RESULTS\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Create results directory if it doesn't exist\n",
        "    results_dir = '../results/'\n",
        "    if not os.path.exists(results_dir):\n",
        "        os.makedirs(results_dir)\n",
        "    \n",
        "    # Save model results\n",
        "    with open(f'{results_dir}multivariate_model_results.pkl', 'wb') as f:\n",
        "        pickle.dump(model_results, f)\n",
        "    print(\"‚úÖ Model results saved to ../results/multivariate_model_results.pkl\")\n",
        "    \n",
        "    # Save comparison results\n",
        "    results_df.to_csv(f'{results_dir}multivariate_model_comparison.csv')\n",
        "    print(\"‚úÖ Model comparison saved to ../results/multivariate_model_comparison.csv\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ Multivariate model training completed!\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No models were successfully trained.\")\n",
        "    print(\"   Please check the model training cells above for errors.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
